name: Google Services Integration Testing

# Comprehensive CI/CD pipeline for Google Services integration testing
# Includes unit tests, integration tests, load testing, and validation

on:
  push:
    branches: [ main, develop, 'feature/*', 'hotfix/*' ]
  pull_request:
    branches: [ main, develop ]
  schedule:
    # Run nightly integration tests
    - cron: '0 2 * * *'
  workflow_dispatch:
    inputs:
      test_suite:
        description: 'Test suite to run'
        required: false
        default: 'all'
        type: choice
        options:
          - all
          - unit
          - integration
          - load
          - e2e
      environment:
        description: 'Environment to test against'
        required: false
        default: 'staging'
        type: choice
        options:
          - staging
          - production
          - mock
      load_test_duration:
        description: 'Load test duration (minutes)'
        required: false
        default: '5'
        type: string

env:
  NODE_VERSION: '18'
  DOCKER_BUILDKIT: 1
  COMPOSE_DOCKER_CLI_BUILD: 1
  TEST_TIMEOUT: 300000
  GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}

jobs:
  # Job 1: Setup and Validation
  setup-validation:
    name: Setup and Validate Environment
    runs-on: ubuntu-latest
    outputs:
      should-run-tests: ${{ steps.changes.outputs.tests }}
      should-run-load-tests: ${{ steps.changes.outputs.load-tests }}
      test-matrix: ${{ steps.matrix.outputs.matrix }}
    
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
        with:
          fetch-depth: 0
      
      - name: Detect changes
        uses: dorny/paths-filter@v2
        id: changes
        with:
          filters: |
            tests:
              - 'tests/**'
              - 'src/**'
              - 'package*.json'
              - 'jest.config.*'
              - '.github/workflows/**'
            load-tests:
              - 'tests/load-testing/**'
              - 'tests/fixtures/**'
              - 'docker-compose*.yml'
      
      - name: Generate test matrix
        id: matrix
        run: |
          if [[ "${{ github.event_name }}" == "schedule" || "${{ github.event.inputs.test_suite }}" == "all" ]]; then
            matrix='{"suite":["unit","integration","load","e2e"]}'
          elif [[ "${{ github.event.inputs.test_suite }}" != "" ]]; then
            matrix='{"suite":["${{ github.event.inputs.test_suite }}"]}'  
          else
            matrix='{"suite":["unit","integration"]}'
          fi
          echo "matrix=$matrix" >> $GITHUB_OUTPUT
      
      - name: Validate Docker Compose configuration
        run: |
          docker-compose -f tests/fixtures/docker-compose.test.yml config -q
      
      - name: Cache dependencies
        uses: actions/cache@v3
        with:
          path: |
            ~/.npm
            ~/.cache/yarn
            node_modules
          key: ${{ runner.os }}-deps-${{ hashFiles('package-lock.json') }}
          restore-keys: |
            ${{ runner.os }}-deps-

  # Job 2: Unit Tests
  unit-tests:
    name: Unit Tests
    runs-on: ubuntu-latest
    needs: setup-validation
    if: needs.setup-validation.outputs.should-run-tests == 'true'
    
    strategy:
      matrix:
        node-version: [18, 20]
        test-group: [core, adapters, protocols, services, streaming]
    
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
      
      - name: Setup Node.js ${{ matrix.node-version }}
        uses: actions/setup-node@v4
        with:
          node-version: ${{ matrix.node-version }}
          cache: 'npm'
      
      - name: Install dependencies
        run: |
          npm ci
          npm run install:test-deps
      
      - name: Type checking
        run: npm run typecheck
      
      - name: Lint code
        run: npm run lint
      
      - name: Run unit tests - ${{ matrix.test-group }}
        run: |
          case "${{ matrix.test-group }}" in
            "core")
              npm run test:unit -- --testMatch="**/src/core/**/*.test.ts"
              ;;
            "adapters")
              npm run test:unit -- --testMatch="**/src/adapters/**/*.test.ts"
              ;;
            "protocols")
              npm run test:unit -- --testMatch="**/src/protocols/**/*.test.ts"
              ;;
            "services")
              npm run test:unit -- --testMatch="**/src/services/**/*.test.ts"
              ;;
            "streaming")
              npm run test:unit -- --testMatch="**/src/streaming/**/*.test.ts"
              ;;
          esac
        env:
          NODE_ENV: test
          CI: true
      
      - name: Upload unit test results
        uses: actions/upload-artifact@v3
        if: always()
        with:
          name: unit-test-results-${{ matrix.node-version }}-${{ matrix.test-group }}
          path: |
            coverage/
            test-results/

  # Job 3: Integration Tests with Mock Services
  integration-tests:
    name: Integration Tests
    runs-on: ubuntu-latest
    needs: setup-validation
    if: needs.setup-validation.outputs.should-run-tests == 'true'
    
    services:
      postgres:
        image: postgres:15-alpine
        env:
          POSTGRES_PASSWORD: test_password
          POSTGRES_USER: test_user
          POSTGRES_DB: gemini_flow_test
        options: >-
          --health-cmd pg_isready
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
        ports:
          - 5432:5432
      
      redis:
        image: redis:7-alpine
        options: >-
          --health-cmd "redis-cli ping"
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
        ports:
          - 6379:6379
    
    strategy:
      matrix:
        test-scenario:
          - streaming-agentspace
          - mariner-veo3
          - co-scientist-imagen4
          - chirp-lyria
          - cross-service-validation
    
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
      
      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}
          cache: 'npm'
      
      - name: Install dependencies
        run: |
          npm ci
          npm run install:full
      
      - name: Setup test environment
        run: |
          # Create test directories
          mkdir -p tests/results tests/artifacts
          
          # Setup environment variables
          echo "NODE_ENV=test" >> $GITHUB_ENV
          echo "TEST_DATABASE_URL=postgresql://test_user:test_password@localhost:5432/gemini_flow_test" >> $GITHUB_ENV
          echo "TEST_REDIS_URL=redis://localhost:6379" >> $GITHUB_ENV
          echo "MOCK_SERVICES=true" >> $GITHUB_ENV
      
      - name: Start mock services
        run: |
          docker-compose -f tests/fixtures/docker-compose.test.yml up -d \
            mock-vertex-ai mock-streaming-api mock-veo3 mock-imagen4 mock-chirp mock-lyria \
            network-simulator prometheus grafana
          
          # Wait for services to be ready
          timeout 60 bash -c 'until curl -f http://localhost:8080/health; do sleep 2; done'
          timeout 60 bash -c 'until curl -f http://localhost:9090/api/v1/status/config; do sleep 2; done'
      
      - name: Run integration tests - ${{ matrix.test-scenario }}
        timeout-minutes: 15
        run: |
          case "${{ matrix.test-scenario }}" in
            "streaming-agentspace")
              npm test -- --testMatch="**/tests/integration/*streaming*agentspace*.test.*" --maxWorkers=2
              ;;
            "mariner-veo3")
              npm test -- --testMatch="**/tests/integration/*mariner*veo3*.test.*" --maxWorkers=1
              ;;
            "co-scientist-imagen4")
              npm test -- --testMatch="**/tests/integration/*co-scientist*imagen4*.test.*" --maxWorkers=2
              ;;
            "chirp-lyria")
              npm test -- --testMatch="**/tests/integration/*chirp*lyria*.test.*" --maxWorkers=2
              ;;
            "cross-service-validation")
              npm test -- --testMatch="**/tests/validation/*.test.*" --maxWorkers=1
              ;;
          esac
        env:
          BASE_URL: http://localhost:8080
          WS_URL: ws://localhost:8080
          TEST_TIMEOUT: ${{ env.TEST_TIMEOUT }}
      
      - name: Collect service logs
        if: failure()
        run: |
          mkdir -p tests/artifacts/logs
          docker-compose -f tests/fixtures/docker-compose.test.yml logs > tests/artifacts/logs/services.log
      
      - name: Upload integration test results
        uses: actions/upload-artifact@v3
        if: always()
        with:
          name: integration-test-results-${{ matrix.test-scenario }}
          path: |
            tests/results/
            tests/artifacts/
            coverage/
      
      - name: Cleanup
        if: always()
        run: |
          docker-compose -f tests/fixtures/docker-compose.test.yml down -v

  # Job 4: Load Testing
  load-tests:
    name: Load Testing
    runs-on: ubuntu-latest
    needs: [setup-validation, integration-tests]
    if: |
      needs.setup-validation.outputs.should-run-load-tests == 'true' &&
      (github.event_name == 'schedule' || 
       github.event.inputs.test_suite == 'load' || 
       github.event.inputs.test_suite == 'all')
    
    strategy:
      matrix:
        load-test-type: [k6, artillery]
        load-profile: [light, medium, heavy]
        exclude:
          - load-test-type: artillery
            load-profile: heavy
    
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
      
      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}
          cache: 'npm'
      
      - name: Install dependencies
        run: npm ci
      
      - name: Start test environment
        run: |
          docker-compose -f tests/fixtures/docker-compose.test.yml up -d
          
          # Wait for all services
          timeout 120 bash -c '
            while ! curl -f http://localhost:8080/health || 
                  ! curl -f http://localhost:8081/health || 
                  ! curl -f http://localhost:8082/health; do 
              sleep 5
            done
          '
      
      - name: Configure load test parameters
        run: |
          duration="${{ github.event.inputs.load_test_duration || '5' }}"
          
          case "${{ matrix.load-profile }}" in
            "light")
              echo "MAX_VUS=10" >> $GITHUB_ENV
              echo "TEST_DURATION=${duration}m" >> $GITHUB_ENV
              ;;
            "medium")
              echo "MAX_VUS=25" >> $GITHUB_ENV
              echo "TEST_DURATION=${duration}m" >> $GITHUB_ENV
              ;;
            "heavy")
              echo "MAX_VUS=50" >> $GITHUB_ENV
              echo "TEST_DURATION=${duration}m" >> $GITHUB_ENV
              ;;
          esac
          
          echo "BASE_URL=http://localhost:8080" >> $GITHUB_ENV
          echo "WS_URL=ws://localhost:8080" >> $GITHUB_ENV
      
      - name: Run K6 load tests
        if: matrix.load-test-type == 'k6'
        run: |
          docker run --rm \
            --network host \
            -v "$PWD/tests/load-testing/k6:/scripts" \
            -v "$PWD/tests/results:/results" \
            -e BASE_URL="$BASE_URL" \
            -e WS_URL="$WS_URL" \
            -e MAX_VUS="$MAX_VUS" \
            -e TEST_DURATION="$TEST_DURATION" \
            grafana/k6:latest run /scripts/google-services-load-test.js \
            --out json=/results/k6-results-${{ matrix.load-profile }}.json \
            --summary-export /results/k6-summary-${{ matrix.load-profile }}.json
      
      - name: Run Artillery load tests
        if: matrix.load-test-type == 'artillery'
        run: |
          npx artillery run \
            tests/load-testing/artillery/google-services-artillery.yml \
            --output tests/results/artillery-results-${{ matrix.load-profile }}.json
          
          npx artillery report tests/results/artillery-results-${{ matrix.load-profile }}.json \
            --output tests/results/artillery-report-${{ matrix.load-profile }}.html
      
      - name: Analyze load test results
        run: |
          mkdir -p tests/artifacts/load-test-analysis
          
          # Generate performance report
          node -e "
            const fs = require('fs');
            const results = '${{ matrix.load-test-type }}' === 'k6' 
              ? JSON.parse(fs.readFileSync('tests/results/k6-results-${{ matrix.load-profile }}.json', 'utf8'))
              : JSON.parse(fs.readFileSync('tests/results/artillery-results-${{ matrix.load-profile }}.json', 'utf8'));
            
            console.log('Load Test Analysis - ${{ matrix.load-profile }} profile');
            console.log('==========================================');
            
            if ('${{ matrix.load-test-type }}' === 'k6') {
              console.log('Request Rate:', results.metrics?.http_reqs?.rate || 'N/A');
              console.log('Error Rate:', results.metrics?.http_req_failed?.rate || 'N/A');
              console.log('Avg Duration:', results.metrics?.http_req_duration?.avg || 'N/A', 'ms');
              console.log('95th Percentile:', results.metrics?.http_req_duration?.['p(95)'] || 'N/A', 'ms');
            } else {
              console.log('Request Count:', results.aggregate?.requestsCompleted || 'N/A');
              console.log('Error Count:', results.aggregate?.errors || 'N/A');
              console.log('Median Response Time:', results.aggregate?.latency?.median || 'N/A', 'ms');
              console.log('95th Percentile:', results.aggregate?.latency?.p95 || 'N/A', 'ms');
            }
          "
      
      - name: Upload load test results
        uses: actions/upload-artifact@v3
        with:
          name: load-test-results-${{ matrix.load-test-type }}-${{ matrix.load-profile }}
          path: |
            tests/results/
            tests/artifacts/
      
      - name: Cleanup load test environment
        if: always()
        run: |
          docker-compose -f tests/fixtures/docker-compose.test.yml down -v

  # Job 5: E2E Tests with Browser Automation
  e2e-tests:
    name: End-to-End Tests
    runs-on: ubuntu-latest
    needs: [setup-validation, integration-tests]
    if: |
      github.event_name == 'schedule' || 
      github.event.inputs.test_suite == 'e2e' || 
      github.event.inputs.test_suite == 'all'
    
    strategy:
      matrix:
        browser: [chromium, firefox]
        test-type: [workflow, user-journey]
    
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
      
      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}
          cache: 'npm'
      
      - name: Install dependencies
        run: |
          npm ci
          npx playwright install --with-deps ${{ matrix.browser }}
      
      - name: Start full test environment
        run: |
          docker-compose -f tests/fixtures/docker-compose.test.yml \
            --profile browser-testing up -d
          
          # Wait for Selenium Grid
          timeout 60 bash -c 'until curl -f http://localhost:4444/status; do sleep 2; done'
      
      - name: Run E2E tests - ${{ matrix.test-type }}
        run: |
          case "${{ matrix.test-type }}" in
            "workflow")
              npm run test:e2e -- --grep="workflow" --browser=${{ matrix.browser }}
              ;;
            "user-journey")
              npm run test:e2e -- --grep="user.*journey" --browser=${{ matrix.browser }}
              ;;
          esac
        env:
          SELENIUM_HUB_URL: http://localhost:4444/wd/hub
          BROWSER: ${{ matrix.browser }}
          HEADLESS: true
      
      - name: Upload E2E test results
        uses: actions/upload-artifact@v3
        if: always()
        with:
          name: e2e-test-results-${{ matrix.browser }}-${{ matrix.test-type }}
          path: |
            tests/e2e/screenshots/
            tests/e2e/videos/
            tests/results/
      
      - name: Cleanup E2E environment
        if: always()
        run: |
          docker-compose -f tests/fixtures/docker-compose.test.yml \
            --profile browser-testing down -v

  # Job 6: Security and Compliance Testing
  security-tests:
    name: Security & Compliance Tests
    runs-on: ubuntu-latest
    needs: setup-validation
    if: |
      github.event_name == 'schedule' || 
      contains(github.event.head_commit.message, '[security]') ||
      github.event.inputs.test_suite == 'all'
    
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
      
      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}
          cache: 'npm'
      
      - name: Install dependencies
        run: npm ci
      
      - name: Run security audit
        run: npm audit --audit-level=moderate
      
      - name: Run SAST scan
        uses: github/super-linter@v4
        env:
          DEFAULT_BRANCH: main
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
          VALIDATE_TYPESCRIPT_ES: true
          VALIDATE_JAVASCRIPT_ES: true
          VALIDATE_JSON: true
          VALIDATE_YAML: true
      
      - name: Run security tests
        run: npm run test:security
        env:
          NODE_ENV: test
      
      - name: Upload security test results
        uses: actions/upload-artifact@v3
        if: always()
        with:
          name: security-test-results
          path: |
            tests/security/results/
            security-report.json

  # Job 7: Test Results Aggregation and Reporting
  test-reporting:
    name: Test Results & Reporting
    runs-on: ubuntu-latest
    needs: [unit-tests, integration-tests, load-tests, e2e-tests, security-tests]
    if: always()
    
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
      
      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}
          cache: 'npm'
      
      - name: Download all test artifacts
        uses: actions/download-artifact@v3
        with:
          path: test-artifacts
      
      - name: Generate comprehensive test report
        run: |
          mkdir -p test-reports
          
          # Create consolidated test report
          node -e "
            const fs = require('fs');
            const path = require('path');
            
            const report = {
              timestamp: new Date().toISOString(),
              workflow: '${{ github.workflow }}',
              run_id: '${{ github.run_id }}',
              commit: '${{ github.sha }}',
              branch: '${{ github.ref_name }}',
              event: '${{ github.event_name }}',
              results: {
                unit_tests: { status: '${{ needs.unit-tests.result }}' },
                integration_tests: { status: '${{ needs.integration-tests.result }}' },
                load_tests: { status: '${{ needs.load-tests.result }}' },
                e2e_tests: { status: '${{ needs.e2e-tests.result }}' },
                security_tests: { status: '${{ needs.security-tests.result }}' }
              },
              artifacts: []
            };
            
            // Collect artifact information
            const artifactDir = './test-artifacts';
            if (fs.existsSync(artifactDir)) {
              const artifacts = fs.readdirSync(artifactDir);
              report.artifacts = artifacts.map(artifact => {
                const artifactPath = path.join(artifactDir, artifact);
                const stats = fs.statSync(artifactPath);
                return {
                  name: artifact,
                  size: stats.size,
                  type: artifact.includes('load-test') ? 'load-test' : 
                        artifact.includes('e2e') ? 'e2e' :
                        artifact.includes('integration') ? 'integration' :
                        artifact.includes('unit') ? 'unit' : 'other'
                };
              });
            }
            
            fs.writeFileSync('test-reports/comprehensive-report.json', JSON.stringify(report, null, 2));
            
            // Log summary
            console.log('='.repeat(60));
            console.log('GOOGLE SERVICES INTEGRATION TEST SUMMARY');
            console.log('='.repeat(60));
            console.log('Workflow:', report.workflow);
            console.log('Run ID:', report.run_id);
            console.log('Commit:', report.commit.substring(0, 8));
            console.log('Branch:', report.branch);
            console.log('');
            console.log('TEST RESULTS:');
            Object.entries(report.results).forEach(([test, result]) => {
              const status = result.status === 'success' ? '‚úÖ PASS' : 
                           result.status === 'failure' ? '‚ùå FAIL' :
                           result.status === 'skipped' ? '‚è≠Ô∏è  SKIP' : '‚ùì UNKNOWN';
              console.log('  ', test.replace(/_/g, ' ').toUpperCase() + ':', status);
            });
            console.log('');
            console.log('ARTIFACTS:', report.artifacts.length);
            console.log('='.repeat(60));
          "
      
      - name: Upload comprehensive test report
        uses: actions/upload-artifact@v3
        with:
          name: comprehensive-test-report
          path: |
            test-reports/
            test-artifacts/
      
      - name: Update PR with test results
        if: github.event_name == 'pull_request'
        uses: actions/github-script@v6
        with:
          script: |
            const fs = require('fs');
            
            let comment = '## üß™ Google Services Integration Test Results\n\n';
            
            const results = {
              'Unit Tests': '${{ needs.unit-tests.result }}',
              'Integration Tests': '${{ needs.integration-tests.result }}',
              'Load Tests': '${{ needs.load-tests.result }}',
              'E2E Tests': '${{ needs.e2e-tests.result }}',
              'Security Tests': '${{ needs.security-tests.result }}'
            };
            
            Object.entries(results).forEach(([test, status]) => {
              const emoji = status === 'success' ? '‚úÖ' : 
                          status === 'failure' ? '‚ùå' :
                          status === 'skipped' ? '‚è≠Ô∏è' : '‚ùì';
              comment += `- ${emoji} **${test}**: ${status}\n`;
            });
            
            comment += '\nüìä Detailed results available in [workflow run](https://github.com/${{ github.repository }}/actions/runs/${{ github.run_id }})';
            
            github.rest.issues.createComment({
              issue_number: context.issue.number,
              owner: context.repo.owner,
              repo: context.repo.repo,
              body: comment
            });
      
      - name: Fail workflow if critical tests failed
        if: |
          needs.unit-tests.result == 'failure' ||
          needs.integration-tests.result == 'failure' ||
          needs.security-tests.result == 'failure'
        run: |
          echo "‚ùå Critical tests failed. Failing the workflow."
          exit 1

  # Job 8: Cleanup and Notifications
  cleanup-notification:
    name: Cleanup & Notifications
    runs-on: ubuntu-latest
    needs: [test-reporting]
    if: always()
    
    steps:
      - name: Clean up Docker resources
        run: |
          docker system prune -af --volumes
      
      - name: Send Slack notification
        if: github.event_name == 'schedule' || github.event_name == 'workflow_dispatch'
        uses: 8398a7/action-slack@v3
        with:
          status: ${{ job.status }}
          channel: '#ci-cd'
          text: |
            Google Services Integration Tests completed
            Repository: ${{ github.repository }}
            Branch: ${{ github.ref_name }}
            Commit: ${{ github.sha }}
            Results: ${{ needs.test-reporting.result }}
        env:
          SLACK_WEBHOOK_URL: ${{ secrets.SLACK_WEBHOOK_URL }}
